{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import yaml\n",
    "from attrdict import AttrMap\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from circlegan.models import Generator\n",
    "from circlegan.models import Discriminator\n",
    "from circlegan.utils import ReplayBuffer\n",
    "from circlegan.utils import LambdaLR\n",
    "from circlegan.utils import Logger\n",
    "from circlegan.utils import weights_init_normal\n",
    "from circlegan.datasets import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "with open('cycle_config.yml', 'r', encoding='UTF-8') as f:\n",
    "    opt = yaml.load(f, Loader=yaml.FullLoader)\n",
    "opt = AttrMap(opt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job number: 0036\n"
     ]
    }
   ],
   "source": [
    "make_manager()\n",
    "n_job = job_increment()\n",
    "\n",
    "print('Job number: {:04d}'.format(n_job))\n",
    "opt.out_dir = os.path.join(opt.out_dir, '{:06}'.format(n_job))\n",
    "os.makedirs(opt.out_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttrMap({'epoch': 0, 'n_epochs': 200, 'batchSize': 1, 'dataroot': './dataset/RICE1', 'lr': 0.002, 'decay_epoch': 50, 'size': 224, 'input_nc': 3, 'output_nc': 3, 'n_cpu': 0, 'cuda': True, 'out_dir': './results\\\\000036', 'manualSeed': 42, 'gpu_ids': [0]})\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  42\n"
     ]
    }
   ],
   "source": [
    "seed_manage(opt)\n",
    "netG_A2B = Generator(opt.input_nc, opt.output_nc)\n",
    "netG_B2A = Generator(opt.output_nc, opt.input_nc)\n",
    "netD_A = Discriminator(opt.input_nc)\n",
    "netD_B = Discriminator(opt.output_nc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\DataspellProjects\\CloudRemoval\\circlegan\\utils.py:121: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Discriminator(\n  (model): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n  )\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net define\n",
    "if opt.cuda:\n",
    "    netG_A2B.cuda()\n",
    "    netG_B2A.cuda()\n",
    "    netD_A.cuda()\n",
    "    netD_B.cuda()\n",
    "\n",
    "netG_A2B.apply(weights_init_normal)\n",
    "netG_B2A.apply(weights_init_normal)\n",
    "netD_A.apply(weights_init_normal)\n",
    "netD_B.apply(weights_init_normal)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Lossess\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Optimizers & LR schedulers\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
    "                               lr=opt.lr, betas=(0.5, 0.999))\n",
    "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
    "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
    "\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G,\n",
    "                                                   lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A,\n",
    "                                                     lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B,\n",
    "                                                     lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Inputs & targets memory allocation\n",
    "Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor\n",
    "input_A = Tensor(opt.batchSize, opt.input_nc, opt.size, opt.size)\n",
    "input_B = Tensor(opt.batchSize, opt.output_nc, opt.size, opt.size)\n",
    "target_real = Variable(Tensor(opt.batchSize).fill_(1.0), requires_grad=False)\n",
    "target_fake = Variable(Tensor(opt.batchSize).fill_(0.0), requires_grad=False)\n",
    "\n",
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "# Dataset loader\n",
    "transforms_ = [transforms.Resize(int(opt.size * 1.12), Image.BICUBIC),\n",
    "               transforms.RandomCrop(opt.size),\n",
    "               # transforms.RandomHorizontalFlip(),\n",
    "               transforms.ToTensor(),\n",
    "               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "dataloader = DataLoader(ImageDataset(opt.dataroot, transforms_=transforms_, unaligned=True),\n",
    "                        batch_size=opt.batchSize, shuffle=True, num_workers=opt.n_cpu)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# Loss plot\n",
    "logger = Logger(opt.n_epochs, len(dataloader))\n",
    "###################################\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(opt.epoch, opt.n_epochs):\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            # Set model input\n",
    "            real_A = Variable(input_A.copy_(batch['A']))\n",
    "            real_B = Variable(input_B.copy_(batch['B']))\n",
    "\n",
    "            ###### Generators A2B and B2A ######\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Identity loss\n",
    "            # G_A2B(B) should equal B if real B is fed\n",
    "            same_B = netG_A2B(real_B)\n",
    "            loss_identity_B = criterion_identity(same_B, real_B) * 5.0\n",
    "            # G_B2A(A) should equal A if real A is fed\n",
    "            same_A = netG_B2A(real_A)\n",
    "            loss_identity_A = criterion_identity(same_A, real_A) * 5.0\n",
    "\n",
    "            # GAN loss\n",
    "            fake_B = netG_A2B(real_A)\n",
    "            pred_fake = netD_B(fake_B)\n",
    "            loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "            fake_A = netG_B2A(real_B)\n",
    "            pred_fake = netD_A(fake_A)\n",
    "            loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "            # Cycle loss\n",
    "            recovered_A = netG_B2A(fake_B)\n",
    "            loss_cycle_ABA = criterion_cycle(recovered_A, real_A) * 10.0\n",
    "\n",
    "            recovered_B = netG_A2B(fake_A)\n",
    "            loss_cycle_BAB = criterion_cycle(recovered_B, real_B) * 10.0\n",
    "\n",
    "            # Total loss\n",
    "            loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "            loss_G.backward()\n",
    "\n",
    "            optimizer_G.step()\n",
    "            ###################################\n",
    "\n",
    "            ###### Discriminator A ######\n",
    "            optimizer_D_A.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = netD_A(real_A)\n",
    "            loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
    "            pred_fake = netD_A(fake_A.detach())\n",
    "            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D_A = (loss_D_real + loss_D_fake) * 0.5\n",
    "            loss_D_A.backward()\n",
    "\n",
    "            optimizer_D_A.step()\n",
    "            ###################################\n",
    "\n",
    "            ###### Discriminator B ######\n",
    "            optimizer_D_B.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = netD_B(real_B)\n",
    "            loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
    "            pred_fake = netD_B(fake_B.detach())\n",
    "            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D_B = (loss_D_real + loss_D_fake) * 0.5\n",
    "            loss_D_B.backward()\n",
    "\n",
    "            optimizer_D_B.step()\n",
    "            ###################################\n",
    "\n",
    "            # Progress report (http://localhost:8097)\n",
    "            logger.log({'loss_G': loss_G, 'loss_G_identity': (loss_identity_A + loss_identity_B),\n",
    "                        'loss_G_GAN': (loss_GAN_A2B + loss_GAN_B2A),\n",
    "                        'loss_G_cycle': (loss_cycle_ABA + loss_cycle_BAB), 'loss_D': (loss_D_A + loss_D_B)},\n",
    "                       images={'real_A': real_A, 'real_B': real_B, 'fake_A': fake_A, 'fake_B': fake_B})\n",
    "\n",
    "        # Update learning rates\n",
    "        lr_scheduler_G.step()\n",
    "        lr_scheduler_D_A.step()\n",
    "        lr_scheduler_D_B.step()\n",
    "\n",
    "        # Save models checkpoints\n",
    "        torch.save(netG_A2B.state_dict(), os.path.join(opt.out_dir, 'netG_A2B.pth'))\n",
    "        torch.save(netG_B2A.state_dict(), os.path.join(opt.out_dir, 'netG_B2A.pth'))\n",
    "        torch.save(netD_A.state_dict(), os.path.join(opt.out_dir, 'netD_A.pth'))\n",
    "        torch.save(netD_B.state_dict(), os.path.join(opt.out_dir, 'netD_B.pth'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:446: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/200 [0001/0400] -- loss_G: 26.3810 | loss_G_identity: 6.9880 | loss_G_GAN: 5.1338 | loss_G_cycle: 14.2592 | loss_D: 2.6828 -- \n",
      "ETA: 2 days, 3:47:47.300325\n",
      "Epoch 001/200 [0002/0400] -- loss_G: 63.8844 | loss_G_identity: 6.9752 | loss_G_GAN: 42.8644 | loss_G_cycle: 14.0448 | loss_D: 44.1110 -- \n",
      "ETA: 1 day, 5:18:26.080773\n",
      "Epoch 001/200 [0003/0400] -- loss_G: 54.4668 | loss_G_identity: 7.7211 | loss_G_GAN: 31.0018 | loss_G_cycle: 15.7439 | loss_D: 30.6595 -- \n",
      "ETA: 23:14:45.108100\n",
      "Epoch 001/200 [0004/0400] -- loss_G: 48.3668 | loss_G_identity: 7.7566 | loss_G_GAN: 24.8570 | loss_G_cycle: 15.7532 | loss_D: 24.3477 -- \n",
      "ETA: 20:07:16.668437\n",
      "Epoch 001/200 [0005/0400] -- loss_G: 42.0607 | loss_G_identity: 7.1372 | loss_G_GAN: 20.4368 | loss_G_cycle: 14.4868 | loss_D: 19.7084 -- \n",
      "ETA: 18:17:56.047590\n",
      "Epoch 001/200 [0006/0400] -- loss_G: 36.9626 | loss_G_identity: 6.6085 | loss_G_GAN: 17.0309 | loss_G_cycle: 13.3232 | loss_D: 17.1607 -- \n",
      "ETA: 17:00:59.935978\n",
      "Epoch 001/200 [0007/0400] -- loss_G: 33.3680 | loss_G_identity: 6.0913 | loss_G_GAN: 15.0535 | loss_G_cycle: 12.2232 | loss_D: 14.7994 -- \n",
      "ETA: 16:07:35.658385\n",
      "Epoch 001/200 [0008/0400] -- loss_G: 30.8741 | loss_G_identity: 5.8419 | loss_G_GAN: 13.3883 | loss_G_cycle: 11.6438 | loss_D: 13.0343 -- \n",
      "ETA: 15:37:42.893503\n",
      "Epoch 001/200 [0009/0400] -- loss_G: 29.2064 | loss_G_identity: 5.7586 | loss_G_GAN: 11.9924 | loss_G_cycle: 11.4554 | loss_D: 11.6920 -- \n",
      "ETA: 15:05:09.019994\n",
      "Epoch 001/200 [0010/0400] -- loss_G: 27.3741 | loss_G_identity: 5.5051 | loss_G_GAN: 10.9478 | loss_G_cycle: 10.9212 | loss_D: 10.6779 -- \n",
      "ETA: 14:42:50.054856\n",
      "Epoch 001/200 [0011/0400] -- loss_G: 26.0948 | loss_G_identity: 5.3866 | loss_G_GAN: 9.9703 | loss_G_cycle: 10.7379 | loss_D: 9.8457 -- \n",
      "ETA: 14:21:52.916420\n",
      "Epoch 001/200 [0012/0400] -- loss_G: 24.5755 | loss_G_identity: 5.1162 | loss_G_GAN: 9.2127 | loss_G_cycle: 10.2466 | loss_D: 9.0499 -- \n",
      "ETA: 14:06:39.974114\n",
      "Epoch 001/200 [0013/0400] -- loss_G: 23.5812 | loss_G_identity: 4.9273 | loss_G_GAN: 8.8044 | loss_G_cycle: 9.8496 | loss_D: 8.4394 -- \n",
      "ETA: 13:53:50.643630\n",
      "Epoch 001/200 [0014/0400] -- loss_G: 22.6649 | loss_G_identity: 4.8118 | loss_G_GAN: 8.2571 | loss_G_cycle: 9.5960 | loss_D: 7.8612 -- \n",
      "ETA: 13:43:10.935348\n",
      "Epoch 001/200 [0015/0400] -- loss_G: 22.4712 | loss_G_identity: 4.9433 | loss_G_GAN: 7.7810 | loss_G_cycle: 9.7470 | loss_D: 7.3564 -- \n",
      "ETA: 13:31:31.184802\n",
      "Epoch 001/200 [0016/0400] -- loss_G: 21.8815 | loss_G_identity: 4.9005 | loss_G_GAN: 7.2995 | loss_G_cycle: 9.6814 | loss_D: 6.9989 -- \n",
      "ETA: 13:23:49.986110\n",
      "Epoch 001/200 [0017/0400] -- loss_G: 21.1565 | loss_G_identity: 4.7470 | loss_G_GAN: 7.0251 | loss_G_cycle: 9.3844 | loss_D: 6.6277 -- \n",
      "ETA: 13:15:20.321090\n",
      "Epoch 001/200 [0018/0400] -- loss_G: 20.8845 | loss_G_identity: 4.7396 | loss_G_GAN: 6.6863 | loss_G_cycle: 9.4586 | loss_D: 6.3230 -- \n",
      "ETA: 13:06:00.344524\n",
      "Epoch 001/200 [0019/0400] -- loss_G: 20.2462 | loss_G_identity: 4.6061 | loss_G_GAN: 6.4291 | loss_G_cycle: 9.2110 | loss_D: 6.0139 -- \n",
      "ETA: 13:00:07.675991\n",
      "Epoch 001/200 [0020/0400] -- loss_G: 19.6340 | loss_G_identity: 4.5024 | loss_G_GAN: 6.1395 | loss_G_cycle: 8.9922 | loss_D: 5.7447 -- \n",
      "ETA: 12:54:49.227372\n",
      "Epoch 001/200 [0021/0400] -- loss_G: 19.0893 | loss_G_identity: 4.4146 | loss_G_GAN: 5.8741 | loss_G_cycle: 8.8006 | loss_D: 5.4861 -- \n",
      "ETA: 12:49:33.595875\n",
      "Epoch 001/200 [0022/0400] -- loss_G: 18.8157 | loss_G_identity: 4.3816 | loss_G_GAN: 5.7008 | loss_G_cycle: 8.7333 | loss_D: 5.2674 -- \n",
      "ETA: 12:44:22.883270\n",
      "Epoch 001/200 [0023/0400] -- loss_G: 18.9956 | loss_G_identity: 4.5159 | loss_G_GAN: 5.5435 | loss_G_cycle: 8.9362 | loss_D: 5.1018 -- \n",
      "ETA: 12:39:13.209739\n",
      "Epoch 001/200 [0024/0400] -- loss_G: 18.7203 | loss_G_identity: 4.4913 | loss_G_GAN: 5.3714 | loss_G_cycle: 8.8577 | loss_D: 4.9305 -- \n",
      "ETA: 12:35:22.982480\n",
      "Epoch 001/200 [0025/0400] -- loss_G: 18.4505 | loss_G_identity: 4.4327 | loss_G_GAN: 5.2797 | loss_G_cycle: 8.7382 | loss_D: 4.7805 -- \n",
      "ETA: 12:31:45.450464\n",
      "Epoch 001/200 [0026/0400] -- loss_G: 18.1419 | loss_G_identity: 4.3840 | loss_G_GAN: 5.1211 | loss_G_cycle: 8.6368 | loss_D: 4.6092 -- \n",
      "ETA: 12:28:36.216482\n",
      "Epoch 001/200 [0027/0400] -- loss_G: 17.8540 | loss_G_identity: 4.3491 | loss_G_GAN: 4.9622 | loss_G_cycle: 8.5427 | loss_D: 4.4635 -- \n",
      "ETA: 12:26:03.293643\n",
      "Epoch 001/200 [0028/0400] -- loss_G: 17.9471 | loss_G_identity: 4.4347 | loss_G_GAN: 4.8415 | loss_G_cycle: 8.6709 | loss_D: 4.3270 -- \n",
      "ETA: 12:23:18.175004\n",
      "Epoch 001/200 [0029/0400] -- loss_G: 17.6882 | loss_G_identity: 4.3917 | loss_G_GAN: 4.7143 | loss_G_cycle: 8.5821 | loss_D: 4.1920 -- \n",
      "ETA: 12:21:20.667275\n",
      "Epoch 001/200 [0030/0400] -- loss_G: 17.5464 | loss_G_identity: 4.3745 | loss_G_GAN: 4.6289 | loss_G_cycle: 8.5430 | loss_D: 4.0834 -- \n",
      "ETA: 12:18:22.789274\n",
      "Epoch 001/200 [0031/0400] -- loss_G: 17.3161 | loss_G_identity: 4.3279 | loss_G_GAN: 4.5295 | loss_G_cycle: 8.4587 | loss_D: 3.9715 -- \n",
      "ETA: 12:16:01.998963\n",
      "Epoch 001/200 [0032/0400] -- loss_G: 17.0360 | loss_G_identity: 4.2802 | loss_G_GAN: 4.4017 | loss_G_cycle: 8.3540 | loss_D: 3.8684 -- \n",
      "ETA: 12:14:34.921003\n",
      "Epoch 001/200 [0033/0400] -- loss_G: 16.9670 | loss_G_identity: 4.2659 | loss_G_GAN: 4.3320 | loss_G_cycle: 8.3691 | loss_D: 3.7778 -- \n",
      "ETA: 12:12:11.605971\n",
      "Epoch 001/200 [0034/0400] -- loss_G: 17.1884 | loss_G_identity: 4.3857 | loss_G_GAN: 4.2082 | loss_G_cycle: 8.5945 | loss_D: 3.7045 -- \n",
      "ETA: 12:10:25.871844\n",
      "Epoch 001/200 [0035/0400] -- loss_G: 16.9826 | loss_G_identity: 4.3318 | loss_G_GAN: 4.1823 | loss_G_cycle: 8.4684 | loss_D: 3.6199 -- \n",
      "ETA: 12:09:10.765017\n",
      "Epoch 001/200 [0036/0400] -- loss_G: 16.9127 | loss_G_identity: 4.3201 | loss_G_GAN: 4.1258 | loss_G_cycle: 8.4668 | loss_D: 3.5454 -- \n",
      "ETA: 12:06:51.569928\n",
      "Epoch 001/200 [0037/0400] -- loss_G: 16.7653 | loss_G_identity: 4.2962 | loss_G_GAN: 4.0446 | loss_G_cycle: 8.4245 | loss_D: 3.5226 -- \n",
      "ETA: 12:04:55.531485\n",
      "Epoch 001/200 [0038/0400] -- loss_G: 17.0053 | loss_G_identity: 4.3846 | loss_G_GAN: 4.0196 | loss_G_cycle: 8.6011 | loss_D: 3.4805 -- \n",
      "ETA: 12:03:36.495933\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\PIL\\ImageFile.py\u001B[0m in \u001B[0;36m_save\u001B[1;34m(im, fp, tile, bufsize)\u001B[0m\n\u001B[0;32m    503\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 504\u001B[1;33m         \u001B[0mfh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfileno\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    505\u001B[0m         \u001B[0mfp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_11692/2346681471.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_11692/3615193446.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     82\u001B[0m                         \u001B[1;34m'loss_G_GAN'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mloss_GAN_A2B\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mloss_GAN_B2A\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     83\u001B[0m                         'loss_G_cycle': (loss_cycle_ABA + loss_cycle_BAB), 'loss_D': (loss_D_A + loss_D_B)},\n\u001B[1;32m---> 84\u001B[1;33m                        images={'real_A': real_A, 'real_B': real_B, 'fake_A': fake_A, 'fake_B': fake_B})\n\u001B[0m\u001B[0;32m     85\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m         \u001B[1;31m# Update learning rates\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\DataspellProjects\\CloudRemoval\\circlegan\\utils.py\u001B[0m in \u001B[0;36mlog\u001B[1;34m(self, losses, images)\u001B[0m\n\u001B[0;32m     58\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m                 self.viz.image(tensor2image(tensor.data), win=self.image_windows[image_name],\n\u001B[1;32m---> 60\u001B[1;33m                                opts={'title': image_name})\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m         \u001B[1;31m# End of epoch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\visdom\\__init__.py\u001B[0m in \u001B[0;36mwrapped_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    387\u001B[0m         \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0m_to_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    388\u001B[0m         \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0m_to_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 389\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    390\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    391\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mwrapped_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\visdom\\__init__.py\u001B[0m in \u001B[0;36mimage\u001B[1;34m(self, img, win, env, opts)\u001B[0m\n\u001B[0;32m   1236\u001B[0m             \u001B[0mimsave_args\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'quality'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopts\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'jpgquality'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1237\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1238\u001B[1;33m         \u001B[0mim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbuf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mformat\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mimage_type\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mimsave_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1239\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1240\u001B[0m         \u001B[0mb64encoded\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mb64\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mb64encode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbuf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetvalue\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'utf-8'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(self, fp, format, **params)\u001B[0m\n\u001B[0;32m   2233\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2234\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2235\u001B[1;33m             \u001B[0msave_handler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2236\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2237\u001B[0m             \u001B[1;31m# do what we can to clean up\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\PIL\\PngImagePlugin.py\u001B[0m in \u001B[0;36m_save\u001B[1;34m(im, fp, filename, chunk, save_all)\u001B[0m\n\u001B[0;32m   1347\u001B[0m         \u001B[0m_write_multiple_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mchunk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrawmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1348\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1349\u001B[1;33m         \u001B[0mImageFile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_save\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_idat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mchunk\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"zip\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrawmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1350\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1351\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0minfo\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\PIL\\ImageFile.py\u001B[0m in \u001B[0;36m_save\u001B[1;34m(im, fp, tile, bufsize)\u001B[0m\n\u001B[0;32m    516\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    517\u001B[0m                 \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 518\u001B[1;33m                     \u001B[0ml\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0md\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbufsize\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    519\u001B[0m                     \u001B[0mfp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0md\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    520\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "torch",
   "language": "python",
   "display_name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}